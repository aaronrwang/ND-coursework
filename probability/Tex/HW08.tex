\documentclass{article}
\usepackage{amsmath, amsfonts, amssymb, amstext, mathtools}
\usepackage{textcomp}
\usepackage[left=1in, right=1.5in]{geometry}
\usepackage{xcolor}

\newcommand{\Emptyset}{\varnothing}
\newcommand{\notsubseteq}{\mathrel{\not\subseteq}}
\newcommand{\union}{\cup}
\newcommand{\intersect}{\cap}
\newcommand{\defeq}{\coloneqq}
\newcommand{\naturals}{\mathbb{N}}
\newcommand{\s}{\mathbb{S}}
\newcommand{\power}{\mathbb{P}}
\newcommand{\expect}{E}
\newcommand{\var}{Var}

\title{Homework 8}
\author{Aaron Wang}
\date{November 15 2024}

\begin{document}
\maketitle
\begin{enumerate}
    \item The joint probability mass (frequency) function of two discrete random
variables, X and Y , is given in the following table:
\[
\begin{array}{c|cccc}
X \backslash Y & 1 & 2 & 3 & 4 \\
\hline
1 & 0.10 & 0.05 & 0.02 & 0.02 \\
2 & 0.05 & 0.20 & 0.05 & 0.02 \\
3 & 0.02 & 0.05 & 0.20 & 0.04 \\
4 & 0.02 & 0.02 & 0.04 & 0.10 \\
\end{array}
\]
Find the marginal probability mass functions of X and Y.

\[
P(X = 1) = 0.10 + 0.05 + 0.02 + 0.02 = 0.19
\]
\[
P(X = 2) = 0.05 + 0.20 + 0.05 + 0.02 = 0.32
\]
\[
P(X = 3) = 0.02 + 0.05 + 0.20 + 0.04 = 0.31
\]
\[
P(X = 4) = 0.02 + 0.02 + 0.04 + 0.10 = 0.18
\]

Thus, the marginal probability mass function of \( X \) is:
\textcolor{red}{
\[
P(X = 1) = 0.19, \quad P(X = 2) = 0.32, \quad P(X = 3) = 0.31, \quad P(X = 4) = 0.18
\]
}

\[
P(Y = 1) = 0.10 + 0.05 + 0.02 + 0.02 = 0.19
\]
\[
P(Y = 2) = 0.05 + 0.20 + 0.05 + 0.02 = 0.32
\]
\[
P(Y = 3) = 0.02 + 0.05 + 0.20 + 0.04 = 0.31
\]
\[
P(Y = 4) = 0.02 + 0.02 + 0.04 + 0.10 = 0.18
\]

Thus, the marginal probability mass function of \( Y \) is:
\textcolor{red}{
\[
P(Y = 1) = 0.19, \quad P(Y = 2) = 0.32, \quad P(Y = 3) = 0.31, \quad P(Y = 4) = 0.18
\]
}
\pagebreak
\item Find the joint and marginal densities corresponding to the CDF:

\[
F(x, y) = (1 - e^{-\alpha x})(1 - e^{-\beta y}), \quad x \geq 0, \, y \geq 0, \, \alpha > 0, \, \beta > 0.
\]
Joint Density
\[
f(x, y) = \frac{\partial^2}{\partial x \partial y} F(x, y)
\]

\[
\frac{\partial}{\partial x} F(x, y) = (1 - e^{-\beta y}) \cdot \frac{\partial}{\partial x} (1 - e^{-\alpha x}) = (1 - e^{-\beta y}) \cdot \alpha e^{-\alpha x}.
\]

\[
\frac{\partial}{\partial y} \left( (1 - e^{-\beta y}) \alpha e^{-\alpha x} \right) = \alpha e^{-\alpha x} \cdot \frac{\partial}{\partial y} (1 - e^{-\beta y}) = \alpha e^{-\alpha x} \beta e^{-\beta y}.
\]

\textcolor{red}{
\[
f(x, y) = \alpha \beta e^{-\alpha x} e^{-\beta y}, \quad x \geq 0, \, y \geq 0, \, \alpha > 0, \, \beta > 0.
\]
}
Marginal Density of \( X \):


\[
f_X(x) = \int_0^\infty f(x, y) \, dy = \int_0^\infty \alpha \beta e^{-\alpha x} e^{-\beta y} \, dy.
\]

\[
f_X(x) = \alpha e^{-\alpha x} \int_0^\infty \beta e^{-\beta y} \, dy.
\]

\[
\int_0^\infty \beta e^{-\beta y} \, dy = 1.
\]
\textcolor{red}{
\[
f_X(x) = \alpha e^{-\alpha x}, \quad x \geq 0, \alpha > 0.
\]
}
Marginal Density of \( Y \):

\[
f_Y(y) = \int_0^\infty f(x, y) \, dx = \int_0^\infty \alpha \beta e^{-\alpha x} e^{-\beta y} \, dx.
\]

\[
f_Y(y) = \beta e^{-\beta y} \int_0^\infty \alpha e^{-\alpha x} \, dx.
\]

\[
\int_0^\infty \alpha e^{-\alpha x} \, dx = 1.
\]
\textcolor{red}{
\[
f_Y(y) = \beta e^{-\beta y}, \quad y \geq 0, \beta > 0 .
\]
}
\pagebreak
\item The management at a fast-food outlet is interested in the joint behavior
of the random variables $Y_1$, defined as the total time between a customerâ€™s arrival at
the store and departure from the service window, and $Y_2$, the time a customer waits
in line before reaching the service window. Because $Y_1$ includes the time a customer
waits in line, we must have $Y_1 \geq Y_2$. The relative frequency distribution of observed
values of $Y_1$ and $Y_2$ can be modeled by the probability density function
\[
f(y_1,y_2)=
\begin{cases}
    e^{-y_1} & 0 \leq y_2 \leq y_1 < \infty \\
    0 & \text{otherwise}
\end{cases}
\]
with time measured in minutes. Find
\begin{enumerate}
    \item $P(Y_1 < 2, Y_2 > 1)$

\[
P(Y_1 < 2, Y_2 > 1) = \int_1^2 \int_1^{y_1}e^{-y_1}dy_2dy_1 = \textcolor{red}{0.0972}
\]
    \item $P(Y_1 \geq 2Y_2)$
\[
P(Y_1 \geq 2Y_2) = \int_0^\infty \int_0^{\frac{y_1}{2}}e^{-y_1}dy_2dy_1 = \textcolor{red}{0.5}
\]
    \item $P(Y_1-Y_2 > 1)$. Notice that $Y_1-Y_2$ denotes the time spent at the service window.
\[
P(Y_1 \geq 2Y_2) = \int_1^\infty \int_{y_1-1}^{y_1}e^{-y_1}dy_2dy_1 = \textcolor{red}{0.3679}
\]
\end{enumerate}
\item Three players play $10$ independent rounds of a game, and each player has probability $\frac{1}{3}$ of winning each round. Find the joint distribution of the numbers of games won by each of the three players.

Observe that this follows a Multinomial Experiment. Thus, the expression for the joint distribution of the number of games won by each of the three players is
\textcolor{red}{
\[
P(X_A = k_A, X_B = k_B, X_C = k_C) = \frac{10!}{k_A! \, k_B! \, k_C!} \left(\frac{1}{3}\right)^{k_A} \left(\frac{1}{3}\right)^{k_B} \left(\frac{1}{3}\right)^{k_C}
\]
}
\pagebreak
\item Let \( F(x, y) \) be the cumulative distribution function (CDF) for a bivariate random variable \( (X, Y) \). For any \( a_1 < a_2 \) and \( b_1 < b_2 \), prove that
\[
P(a_1 < X \leq a_2, b_1 < Y \leq b_2) = F(a_2, b_2) - F(a_1, b_2) - F(a_2, b_1) + F(a_1, b_1).
\]
\begin{align*}
P(X \leq a_2, Y \leq b_2) &= F(a_2, b_2) \\
P(X \leq a_1, Y \leq b_2) &= F(a_1, b_2) \\
P(X \leq a_2, Y \leq b_1) &= F(a_2, b_1) \\
P(X \leq a_1, Y \leq b_1) &= F(a_1, b_1)
\end{align*}
\begin{align*}
P(a_1 < X \leq a_2, Y \leq b_2) &= F(a_2, b_2) - F(a_1, b_2) \\
P(a_1 < X \leq a_2, Y \leq b_1) &= F(a_2, b_1) - F(a_1, b_1)
\end{align*}
\[
P(a_1 < X \leq a_2, b_1 < Y \leq b_2) = \big(F(a_2, b_2) - F(a_1, b_2)\big) - \big(F(a_2, b_1) - F(a_1, b_1)\big)
\]
\[
P(a_1 < X \leq a_2, b_1 < Y \leq b_2) = F(a_2, b_2) - F(a_1, b_2) - F(a_2, b_1) + F(a_1, b_1)
\]

\end{enumerate}
\end{document}